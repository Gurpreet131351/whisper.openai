{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47365772",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-26T09:36:46.755853Z",
     "iopub.status.busy": "2024-04-26T09:36:46.755524Z",
     "iopub.status.idle": "2024-04-26T09:37:22.011887Z",
     "shell.execute_reply": "2024-04-26T09:37:22.010778Z"
    },
    "papermill": {
     "duration": 35.262976,
     "end_time": "2024-04-26T09:37:22.014488",
     "exception": false,
     "start_time": "2024-04-26T09:36:46.751512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\r\n",
      "  Downloading openai-whisper-20231117.tar.gz (798 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting triton<3,>=2.0.0 (from openai-whisper)\r\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (0.58.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (1.26.4)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (2.1.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (4.66.1)\r\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (10.2.0)\r\n",
      "Collecting tiktoken (from openai-whisper)\r\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.1)\r\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper) (0.41.1)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2023.12.25)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\r\n",
      "Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\r\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=04638de4ade0bd79b955e8df95b2e5b3e99762d3c9ec2738f22849ff9ac7b7da\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\r\n",
      "Successfully built openai-whisper\r\n",
      "Installing collected packages: triton, tiktoken, openai-whisper\r\n",
      "Successfully installed openai-whisper-20231117 tiktoken-0.6.0 triton-2.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3623ef42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:37:22.036111Z",
     "iopub.status.busy": "2024-04-26T09:37:22.035802Z",
     "iopub.status.idle": "2024-04-26T09:37:28.266943Z",
     "shell.execute_reply": "2024-04-26T09:37:28.266069Z"
    },
    "papermill": {
     "duration": 6.244542,
     "end_time": "2024-04-26T09:37:28.269401",
     "exception": false,
     "start_time": "2024-04-26T09:37:22.024859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc8bb8b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:37:28.290192Z",
     "iopub.status.busy": "2024-04-26T09:37:28.289387Z",
     "iopub.status.idle": "2024-04-26T09:37:28.295143Z",
     "shell.execute_reply": "2024-04-26T09:37:28.294306Z"
    },
    "papermill": {
     "duration": 0.018067,
     "end_time": "2024-04-26T09:37:28.297038",
     "exception": false,
     "start_time": "2024-04-26T09:37:28.278971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_file, model, device):\n",
    "    audio = whisper.load_audio(audio_file)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    mel = whisper.log_mel_spectrogram(audio).to(device)\n",
    "    \n",
    "    options = whisper.DecodingOptions(language=\"hi\") # setting decoding options to transcribe only from hindi\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24783578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:37:28.317356Z",
     "iopub.status.busy": "2024-04-26T09:37:28.317050Z",
     "iopub.status.idle": "2024-04-26T09:37:28.326196Z",
     "shell.execute_reply": "2024-04-26T09:37:28.325505Z"
    },
    "papermill": {
     "duration": 0.021672,
     "end_time": "2024-04-26T09:37:28.328158",
     "exception": false,
     "start_time": "2024-04-26T09:37:28.306486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"using {device} as accelerator\")\n",
    "    \n",
    "    model = whisper.load_model(\"base\")\n",
    "    model.to(device)\n",
    "    \n",
    "    audio_directory = \"/kaggle/input/gv-eval-3h/GV_Eval_3h/Audio\"\n",
    "    \n",
    "    transcriptions = []\n",
    "    \n",
    "    count = 0\n",
    "    for audio_file in os.listdir(audio_directory):\n",
    "        if audio_file.endswith(\".mp3\"):\n",
    "            audio_path = os.path.join(audio_directory, audio_file)\n",
    "            transcription = transcribe_audio(audio_path, model, device)\n",
    "            transcriptions.append((audio_file, transcription))\n",
    "            count += 1\n",
    "            if count % 10 == 0:\n",
    "                print(f\"Total {count} files transcribed till now\")\n",
    "    print(\"\\n\\n\\n\\n-------------------------\")\n",
    "    print(f\"A total of {count} files were transcribed\")\n",
    "    df = pd.DataFrame(transcriptions, columns=[\"Audio File\", \"Transcription\"])\n",
    "    \n",
    "    df.to_excel(\"transcription.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef19bd89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:37:28.348288Z",
     "iopub.status.busy": "2024-04-26T09:37:28.347966Z",
     "iopub.status.idle": "2024-04-26T10:01:44.158410Z",
     "shell.execute_reply": "2024-04-26T10:01:44.157600Z"
    },
    "papermill": {
     "duration": 1455.8231,
     "end_time": "2024-04-26T10:01:44.160761",
     "exception": false,
     "start_time": "2024-04-26T09:37:28.337661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda as accelerator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 165MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 10 files transcribed till now\n",
      "Total 20 files transcribed till now\n",
      "Total 30 files transcribed till now\n",
      "Total 40 files transcribed till now\n",
      "Total 50 files transcribed till now\n",
      "Total 60 files transcribed till now\n",
      "Total 70 files transcribed till now\n",
      "Total 80 files transcribed till now\n",
      "Total 90 files transcribed till now\n",
      "Total 100 files transcribed till now\n",
      "Total 110 files transcribed till now\n",
      "Total 120 files transcribed till now\n",
      "Total 130 files transcribed till now\n",
      "Total 140 files transcribed till now\n",
      "Total 150 files transcribed till now\n",
      "Total 160 files transcribed till now\n",
      "Total 170 files transcribed till now\n",
      "Total 180 files transcribed till now\n",
      "Total 190 files transcribed till now\n",
      "Total 200 files transcribed till now\n",
      "Total 210 files transcribed till now\n",
      "Total 220 files transcribed till now\n",
      "Total 230 files transcribed till now\n",
      "Total 240 files transcribed till now\n",
      "Total 250 files transcribed till now\n",
      "Total 260 files transcribed till now\n",
      "Total 270 files transcribed till now\n",
      "Total 280 files transcribed till now\n",
      "Total 290 files transcribed till now\n",
      "Total 300 files transcribed till now\n",
      "Total 310 files transcribed till now\n",
      "Total 320 files transcribed till now\n",
      "Total 330 files transcribed till now\n",
      "Total 340 files transcribed till now\n",
      "Total 350 files transcribed till now\n",
      "Total 360 files transcribed till now\n",
      "Total 370 files transcribed till now\n",
      "Total 380 files transcribed till now\n",
      "Total 390 files transcribed till now\n",
      "Total 400 files transcribed till now\n",
      "Total 410 files transcribed till now\n",
      "Total 420 files transcribed till now\n",
      "Total 430 files transcribed till now\n",
      "Total 440 files transcribed till now\n",
      "Total 450 files transcribed till now\n",
      "Total 460 files transcribed till now\n",
      "Total 470 files transcribed till now\n",
      "Total 480 files transcribed till now\n",
      "Total 490 files transcribed till now\n",
      "Total 500 files transcribed till now\n",
      "Total 510 files transcribed till now\n",
      "Total 520 files transcribed till now\n",
      "Total 530 files transcribed till now\n",
      "Total 540 files transcribed till now\n",
      "Total 550 files transcribed till now\n",
      "Total 560 files transcribed till now\n",
      "Total 570 files transcribed till now\n",
      "Total 580 files transcribed till now\n",
      "Total 590 files transcribed till now\n",
      "Total 600 files transcribed till now\n",
      "Total 610 files transcribed till now\n",
      "Total 620 files transcribed till now\n",
      "Total 630 files transcribed till now\n",
      "Total 640 files transcribed till now\n",
      "Total 650 files transcribed till now\n",
      "Total 660 files transcribed till now\n",
      "Total 670 files transcribed till now\n",
      "Total 680 files transcribed till now\n",
      "Total 690 files transcribed till now\n",
      "Total 700 files transcribed till now\n",
      "Total 710 files transcribed till now\n",
      "Total 720 files transcribed till now\n",
      "Total 730 files transcribed till now\n",
      "Total 740 files transcribed till now\n",
      "Total 750 files transcribed till now\n",
      "Total 760 files transcribed till now\n",
      "Total 770 files transcribed till now\n",
      "Total 780 files transcribed till now\n",
      "Total 790 files transcribed till now\n",
      "Total 800 files transcribed till now\n",
      "Total 810 files transcribed till now\n",
      "Total 820 files transcribed till now\n",
      "Total 830 files transcribed till now\n",
      "Total 840 files transcribed till now\n",
      "Total 850 files transcribed till now\n",
      "Total 860 files transcribed till now\n",
      "Total 870 files transcribed till now\n",
      "Total 880 files transcribed till now\n",
      "Total 890 files transcribed till now\n",
      "Total 900 files transcribed till now\n",
      "Total 910 files transcribed till now\n",
      "Total 920 files transcribed till now\n",
      "Total 930 files transcribed till now\n",
      "Total 940 files transcribed till now\n",
      "Total 950 files transcribed till now\n",
      "Total 960 files transcribed till now\n",
      "Total 970 files transcribed till now\n",
      "Total 980 files transcribed till now\n",
      "Total 990 files transcribed till now\n",
      "Total 1000 files transcribed till now\n",
      "Total 1010 files transcribed till now\n",
      "Total 1020 files transcribed till now\n",
      "Total 1030 files transcribed till now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------------------\n",
      "A total of 1032 files were transcribed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b602e",
   "metadata": {
    "papermill": {
     "duration": 0.01853,
     "end_time": "2024-04-26T10:01:44.198348",
     "exception": false,
     "start_time": "2024-04-26T10:01:44.179818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4882503,
     "sourceId": 8232741,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1503.103881,
   "end_time": "2024-04-26T10:01:46.705587",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-26T09:36:43.601706",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
